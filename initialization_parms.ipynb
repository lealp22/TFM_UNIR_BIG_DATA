{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymongo in c:\\users\\lealp\\anaconda3\\lib\\site-packages (4.6.1)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in c:\\users\\lealp\\anaconda3\\lib\\site-packages (from pymongo) (2.4.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\lealp\\anaconda3\\lib\\site-packages (0.21.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pymongo\n",
    "%pip install python-dotenv\n",
    "# %pip install requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importación de librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lealp\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Users\\lealp\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "c:\\Users\\lealp\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n",
      "c:\\Users\\lealp\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "C:\\Users\\lealp\\AppData\\Local\\Temp\\ipykernel_13356\\2074460846.py:5: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pymongo\n",
    "# import requests\n",
    "# import time\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "# from web3 import Web3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carga los secretos del archivo **.env**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1UXP**********R783\n",
      "mongodb://local*****/\n"
     ]
    }
   ],
   "source": [
    "# Carga los secretos del archivo .env\n",
    "load_dotenv()\n",
    "\n",
    "# Accede a los valores definidos en .env\n",
    "APIKEY_ETHERSCAN = os.getenv(\"APIKEY_ETHERSCAN\")\n",
    "MONGODB_SERVER = os.getenv(\"MONGODB_SERVER\")\n",
    "\n",
    "print(APIKEY_ETHERSCAN[:4]+('*'*10)+APIKEY_ETHERSCAN[-4:])\n",
    "print(MONGODB_SERVER[:15] + '*****' + MONGODB_SERVER[25:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conexión MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'version': '5.0.3', 'gitVersion': '657fea5a61a74d7a79df7aff8e4bcf0bc742b748', 'targetMinOS': 'Windows 7/Windows Server 2008 R2', 'modules': [], 'allocator': 'tcmalloc', 'javascriptEngine': 'mozjs', 'sysInfo': 'deprecated', 'versionArray': [5, 0, 3, 0], 'openssl': {'running': 'Windows SChannel'}, 'buildEnvironment': {'distmod': 'windows', 'distarch': 'x86_64', 'cc': 'cl: Microsoft (R) C/C++ Optimizing Compiler Version 19.26.28806 for x64', 'ccflags': '/nologo /WX /FImongo/platform/basic.h /EHsc /W3 /wd4068 /wd4244 /wd4267 /wd4290 /wd4351 /wd4355 /wd4373 /wd4800 /wd4251 /wd4291 /we4013 /we4099 /we4930 /errorReport:none /MD /O2 /Oy- /bigobj /utf-8 /permissive- /Zc:__cplusplus /Zc:sizedDealloc /volatile:iso /diagnostics:caret /std:c++17 /Gw /Gy /Zc:inline', 'cxx': 'cl: Microsoft (R) C/C++ Optimizing Compiler Version 19.26.28806 for x64', 'cxxflags': '/TP', 'linkflags': '/nologo /DEBUG /INCREMENTAL:NO /LARGEADDRESSAWARE /OPT:REF', 'target_arch': 'x86_64', 'target_os': 'windows', 'cppdefines': 'SAFEINT_USE_INTRINSICS 0 PCRE_STATIC NDEBUG BOOST_ALL_NO_LIB _UNICODE UNICODE _SILENCE_CXX17_ALLOCATOR_VOID_DEPRECATION_WARNING _SILENCE_CXX17_OLD_ALLOCATOR_MEMBERS_DEPRECATION_WARNING _SILENCE_CXX17_CODECVT_HEADER_DEPRECATION_WARNING _CONSOLE _CRT_SECURE_NO_WARNINGS _SCL_SECURE_NO_WARNINGS _WIN32_WINNT 0x0A00 BOOST_USE_WINAPI_VERSION 0x0A00 NTDDI_VERSION 0x0A000000 BOOST_THREAD_VERSION 5 BOOST_THREAD_USES_DATETIME BOOST_SYSTEM_NO_DEPRECATED BOOST_MATH_NO_LONG_DOUBLE_MATH_FUNCTIONS BOOST_ENABLE_ASSERT_DEBUG_HANDLER BOOST_LOG_NO_SHORTHAND_NAMES BOOST_LOG_USE_NATIVE_SYSLOG BOOST_LOG_WITHOUT_THREAD_ATTR ABSL_FORCE_ALIGNED_ACCESS'}, 'bits': 64, 'debug': False, 'maxBsonObjectSize': 16777216, 'storageEngines': ['devnull', 'ephemeralForTest', 'wiredTiger'], 'ok': 1.0}\n"
     ]
    }
   ],
   "source": [
    "mongoClient = pymongo.MongoClient(MONGODB_SERVER, serverSelectionTimeoutMS=5000)\n",
    "\n",
    "try:\n",
    "    print(mongoClient.server_info())\n",
    "except Exception:\n",
    "    print(\"Unable to connect to the server.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definición BBDD, colecciones e indices en MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base de Datos\n",
    "mongoDb = mongoClient['web3_tfm']\n",
    "\n",
    "# Colección Históricos Bloques\n",
    "collection_block_history = mongoDb['block_history']\n",
    "\n",
    "# Crear índice único para 'date' e indice para 'max_block_number'\n",
    "collection_block_history.create_index('date')\n",
    "collection_block_history.create_index('max_block_number')\n",
    "\n",
    "# Colección Directorio de Cuentas\n",
    "collection_account_directory = mongoDb['account_directory']\n",
    "\n",
    "# Colección Directorio de Redes\n",
    "collection_network_directory = mongoDb['network_directory']\n",
    "\n",
    "# Colección Tipo de Cambio Ether / Dollar Americano\n",
    "collection_eth_usd_quotes = mongoDb['eth_usd_quotes']\n",
    "\n",
    "# Colección Tipo de Cambio Ether / Euro\n",
    "collection_eth_eur_quotes = mongoDb['eth_eur_quotes']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga colección *block_history*\n",
    "Lectura fichero CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date  max_block_number\n",
      "0  2015-07-30              6911\n",
      "1  2015-07-31             13774\n",
      "2  2015-08-01             19067\n",
      "3  2015-08-02             24425\n",
      "4  2015-08-03             29705\n"
     ]
    }
   ],
   "source": [
    "csv_file = r\"data\\ethereum-historico-bloques-fin-dia.csv\"\n",
    "\n",
    "# Leemos el archivo CSV\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Imprimimos la cabecera del DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Borra todos los datos en la colección para cargar todo el contenido del fichero CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de documentos eliminados: 0\n"
     ]
    }
   ],
   "source": [
    "result = collection_block_history.delete_many({})\n",
    "\n",
    "# Comprueba el número de documentos eliminados\n",
    "print(f\"Número de documentos eliminados: {result.deleted_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparación de datos\n",
    "- Añade el identificador de la red a la que pertenecen los bloques (1 - Ethereum)  \n",
    "- Añade el número del día de la semana para facilitar el filtrado de los datos  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>max_block_number</th>\n",
       "      <th>id_network</th>\n",
       "      <th>day_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-07-30</td>\n",
       "      <td>6911</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>13774</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-08-01</td>\n",
       "      <td>19067</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-08-02</td>\n",
       "      <td>24425</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-08-03</td>\n",
       "      <td>29705</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  max_block_number  id_network  day_week\n",
       "0  2015-07-30              6911           1         3\n",
       "1  2015-07-31             13774           1         4\n",
       "2  2015-08-01             19067           1         5\n",
       "3  2015-08-02             24425           1         6\n",
       "4  2015-08-03             29705           1         0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se incluye un 3º atributo para identificar la red blockchain de la que se ha obtenido los datos\n",
    "df[\"id_network\"] = 1\n",
    "df['day_week'] = pd.to_datetime(df['date']).dt.dayofweek\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carga de datos en MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo CSV data\\ethereum-historico-bloques-fin-dia.csv cargado en MongoDB 'block_history'.\n",
      "3123 documentos insertados.\n"
     ]
    }
   ],
   "source": [
    "# Convertir el DataFrame de Pandas a una lista de diccionarios\n",
    "data = df.to_dict(orient='records')\n",
    "\n",
    "# Insertar los datos en la colección MongoDB\n",
    "result = collection_block_history.insert_many(data)\n",
    "\n",
    "# Imprime el resultado\n",
    "print(f\"Archivo CSV {csv_file} cargado en MongoDB 'block_history'.\")\n",
    "print(f\"{len(result.inserted_ids)} documentos insertados.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'date': '2015-07-30', 'max_block_number': 6911, 'id_network': 1, 'day_week': 3, '_id': ObjectId('65d140b53cd0e5823d7dda18')}\n"
     ]
    }
   ],
   "source": [
    "print(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecciona unicamente las bloques a partir del año 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 [16315361, 16322532, 16329700, 16336870, 16344023, 16351183, 16358346, 16365511, 16372678, 16379844]\n"
     ]
    }
   ],
   "source": [
    "filtro_fecha = df[\"date\"] > \"2022-12-31\"\n",
    "numeros_bloque = df[filtro_fecha][\"max_block_number\"][:10].tolist()\n",
    "print(len(numeros_bloque), numeros_bloque)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Función para la carga de colecciones a partir de parámetros en ficheros CSV**\n",
    "- Lee ficheros CSV\n",
    "- Borra todos los elementos en la colección\n",
    "- Inserta datos en fichero CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_collection_from_data(collection, dataframe):\n",
    "    \n",
    "    # Convertir el DataFrame de Pandas a una lista de diccionarios\n",
    "    data = dataframe.to_dict(orient='records')\n",
    "    \n",
    "    # Borrado de datos para cargar todo el contenido del fichero CSV\n",
    "    result = collection.delete_many({})\n",
    "\n",
    "    # Comprueba el número de documentos eliminados\n",
    "    print(f\"\\nNúmero de documentos eliminados: {result.deleted_count}\")\n",
    "    \n",
    "    # Insertar los datos en la colección MongoDB\n",
    "    result = collection.insert_many(data)\n",
    "\n",
    "    # Imprime el resultado\n",
    "    print(f\"\\nArchivo CSV {csv_file} cargado en base de datos. Documentos insertados: {len(result.inserted_ids)}\")\n",
    "    print(\"Elemento insertado:\")\n",
    "    print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_collection(collection, csv_file):\n",
    "    \n",
    "    # Leer el archivo CSV con Pandas\n",
    "    df = pd.read_csv(csv_file, delimiter=';')\n",
    "    print(df.head())\n",
    "    \n",
    "    load_collection_from_data(collection, df)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga colección *account_directory*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   from_network  to_network  layer  \\\n",
      "0             1       42161      1   \n",
      "1             1       42161      1   \n",
      "2             1       42161      1   \n",
      "3             1       42161      1   \n",
      "4             1       42161      1   \n",
      "\n",
      "                                      address description  \\\n",
      "0  0x4Dbd4fc535Ac27206064B68FfCf827b0A60BAB3f    Arbitrum   \n",
      "1  0xa3A7B6F88361F48403514059F1F16C8E78d60EeC    Arbitrum   \n",
      "2  0xcEe284F754E854890e311e3280b767F80797180d    Arbitrum   \n",
      "3  0xd92023E9d9911199a6711321D1277285e6d4e2db    Arbitrum   \n",
      "4  0xA10c7CE4b876998858b1a9E12b10092229539400    Arbitrum   \n",
      "\n",
      "                                    full_description  is_transactions  \\\n",
      "0  Arbitrum Official Bridge Contract - Delayed Inbox             True   \n",
      "1                     Arbitrum One: L1 ERC20 Gateway            False   \n",
      "2              Arbitrum One: L1 Arb - Custom Gateway            False   \n",
      "3                Arbitrum One: Wrapped Ether Gateway            False   \n",
      "4                            Arbitrum: DAI L1 Escrow            False   \n",
      "\n",
      "   is_balance  \n",
      "0       False  \n",
      "1       False  \n",
      "2       False  \n",
      "3       False  \n",
      "4       False  \n",
      "\n",
      "Número de documentos eliminados: 11\n",
      "\n",
      "Archivo CSV data/account_directory.csv cargado en base de datos. Documentos insertados: 11\n",
      "Elemento insertado:\n",
      "{'from_network': 1, 'to_network': 42161, 'layer': 1, 'address': '0x4Dbd4fc535Ac27206064B68FfCf827b0A60BAB3f', 'description': 'Arbitrum', 'full_description': 'Arbitrum Official Bridge Contract - Delayed Inbox', 'is_transactions': True, 'is_balance': False, '_id': ObjectId('65d5034e3ebb3c4bb440e411')}\n"
     ]
    }
   ],
   "source": [
    "# Ruta archivo CSV\n",
    "csv_file = r'data/account_directory.csv'\n",
    "\n",
    "# Carga de datos\n",
    "load_collection(collection_account_directory, csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga colección *network_directory*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id  id_hex          value       description  isMainnet\n",
      "0      1     0x1       ethereum          Ethereum       True\n",
      "1  42161  0xa4b1       arbitrum      Arbitrum One       True\n",
      "2  42170  0xa4ba  arbitrum_nova     Arbitrum Nova       True\n",
      "3     10     0xa       optimism  Optimism Mainnet       True\n",
      "4    137    0x89        polygon   Polygon Mainnet       True\n",
      "\n",
      "Número de documentos eliminados: 0\n",
      "\n",
      "Archivo CSV data/network_directory.csv cargado en base de datos. Documentos insertados: 96\n",
      "Elemento insertado:\n",
      "{'id': 1, 'id_hex': '0x1', 'value': 'ethereum', 'description': 'Ethereum', 'isMainnet': True, '_id': ObjectId('65d140ce3cd0e5823d7de656')}\n"
     ]
    }
   ],
   "source": [
    "# Ruta archivo CSV\n",
    "csv_file = r'data/network_directory.csv'\n",
    "\n",
    "# Carga de datos\n",
    "load_collection(collection_network_directory, csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga colección *eth_usd_quotes*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                snapped_at        price   market_cap total_volume\n",
      "0  2015-08-07 00:00:00 UTC      2,83162            0        90622\n",
      "1  2015-08-08 00:00:00 UTC      1,33075     80339475       368070\n",
      "2  2015-08-10 00:00:00 UTC  0,687585709  41556309,21  400464,0745\n",
      "3  2015-08-11 00:00:00 UTC  1,067378879  64539006,31  1518998,205\n",
      "4  2015-08-12 00:00:00 UTC  1,256613175  76013261,05  2073893,345\n",
      "\n",
      "Número de documentos eliminados: 0\n",
      "\n",
      "Archivo CSV data/eth-usd-max.csv cargado en base de datos. Documentos insertados: 3119\n",
      "Elemento insertado:\n",
      "{'snapped_at': '2015-08-07 00:00:00 UTC', 'price': '2,83162', 'market_cap': '0', 'total_volume': '90622', '_id': ObjectId('65d5a5733ebb3c4bb440e41c')}\n"
     ]
    }
   ],
   "source": [
    "# Ruta archivo CSV\n",
    "csv_file = r'data/eth-usd-max.csv'\n",
    "\n",
    "# Carga de datos\n",
    "load_collection(collection_eth_usd_quotes, csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga colección *eth_eur_quotes*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Fecha   Último  Apertura   Máximo   Mínimo     Vol.  % var.\n",
      "0 2024-02-20  3015.38   2944.79  3030.61  2879.82  674.55K    2.40\n",
      "1 2024-02-19  2944.80   2880.16  2983.48  2859.82  478.68K    2.25\n",
      "2 2024-02-18  2880.10   2785.90  2892.79  2765.97  391.11K    3.38\n",
      "3 2024-02-17  2785.90   2801.80  2804.17  2721.21  251.97K   -0.57\n",
      "4 2024-02-16  2801.80   2822.59  2856.76  2759.52  401.19K   -0.74\n",
      "\n",
      "Número de documentos eliminados: 416\n",
      "\n",
      "Archivo CSV data/Histórico-ether-euro-investing.csv cargado en base de datos. Documentos insertados: 416\n",
      "Elemento insertado:\n",
      "{'Fecha': Timestamp('2024-02-20 00:00:00'), 'Último': 3015.38, 'Apertura': 2944.79, 'Máximo': 3030.61, 'Mínimo': 2879.82, 'Vol.': '674.55K', '% var.': 2.4, '_id': ObjectId('65dbdf756e580e93a40f14c1')}\n"
     ]
    }
   ],
   "source": [
    "# Ruta archivo CSV\n",
    "csv_file = r'data/Histórico-ether-euro-investing.csv'\n",
    "\n",
    "# Leer el archivo CSV en un DataFrame de Pandas\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Convertir el primer campo a formato de fecha\n",
    "df['date'] = pd.to_datetime(df['Fecha'], format='%d.%m.%Y')\n",
    "\n",
    "# Eliminar el punto y reemplazar la coma por punto como separador decimal en los campos 2, 3, 4 y 5\n",
    "for col in df.columns[1:5]:\n",
    "    df[col] = df[col].str.replace('.', '').str.replace(',', '.').astype(float)\n",
    "\n",
    "# Reemplazar la coma por punto como separador decimal en el campo \"Vol.\"\n",
    "df['volume'] = df['Vol.'].str.replace(',', '.')\n",
    "\n",
    "# Reemplazar la coma por punto como separador decimal en el campo \"% var.\"\n",
    "df['variation %'] = df['% var.'].str.replace(',', '.').str.rstrip('%').astype(float)\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "load_collection_from_data(collection_eth_eur_quotes, df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
